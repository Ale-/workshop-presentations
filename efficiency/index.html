<!doctype html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <title>Algoritmos y eficiencia</title>
        <meta name="description" content="Algoritmos y eficiencia">
                <meta name="author" content="Ale" />
                 
        <meta name="apple-mobile-web-app-capable" content="yes" />
        <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
         
        <link rel="stylesheet" href="../../revealjs/css/reveal.css">
                <link rel="stylesheet" href="../../revealjs/css/theme/black.css" id="theme">
                <!-- For syntax highlighting -->
                <link rel="stylesheet" href="../../revealjs/lib/css/zenburn.css">
                 
        <!-- If the query includes 'print-pdf', use the PDF print sheet -->
        <script>
        document.write( '<link rel="stylesheet" href="../../revealjs/css/print/' +
        ( window.location.search.match( /print-pdf/gi ) ? 'pdf' : 'paper' ) +
        '.css" type="text/css" media="print">' );
        </script>
        
        <!--Our style here-->
        <link rel="stylesheet" href="style/style.css">
 
        <!--[if lt IE 9]>
        <script src="lib/js/html5shiv.js"></script>
        <![endif]-->
            </head>
    <body>
                <div class="reveal">
        <!-- Any section element inside of this container is displayed as a slide -->
        <div class="slides">
         
                 
        <section id="referencias" class="level1">
        <h1>Referencias</h1>
        <p><strong>Repo de processing con los ejercicios</strong> <a href="">https://github.com/Ale-/codeup</a></p>
        <p><strong>Presentación</strong> <a href="">http://workshops.wwb.cc/efficiency</a></p>
        </section>
        <section id="algoritmos" class="level1">
        <h1>Algoritmos</h1>
        <section id="qué-son" class="level2">
        <h2>Qué son</h2>
        <p>Un algoritmo es la serie ordenada de instrucciones que permite describir de manera lógica un procedimiento. Aunque el nombre, proveniente del campo de las matemáticas, parece aludir a una componente matemática compleja, esto no tiene por qué ser necesariamente así. El análogo más cercano a un algoritmo puede ser el de una receta de cocina:</p>
        </section>
        <section id="receta-de-una-tortilla-de-patatas" class="level2">
        <h2>Receta de una tortilla de patatas</h2>
        <ol type="1">
        <li>Coge 6 huevos grandes</li>
        <li>Coge 6 patatas pequeñas</li>
        <li>Pela, corta y fríe las patatas</li>
        <li>Echas los 6 huevos en un bol y bátelos</li>
        <li>Mézclalo todo</li>
        <li>Caliéntalo</li>
        </ol>
        <pre><code>//Una posible representación en código de la misma receta
        
        int n = 6;
        Huevo[] huevos = new Huevo[n];
        Patata[] patatas = new Patata[n];
        for(int i = 0; i &lt; n; i++){
            peelAndSlice(patatas[i]);
            fry(patatas[i]);
        }
        ScrambledEggs mezcla = scramble(Huevos);
        if( areFried(patatas) ) {
            cook( mix(patatas, mezcla) );
        }
        </code></pre>
        </section>
        <section id="en-resumen" class="level2">
        <h2>En resumen</h2>
        <p>Un algoritmo es una serie ordenada de instrucciones, compuesta básicamente por expresiones condicionales (<em>if-else</em>, <em>while</em>...) e iteraciones (<em>for</em>, <em>foreach</em>...). Hacer buenos algoritmos tiene más que ver con la lógica, el sentido común y la capacidad de hacer modelos lógicos que con el conocimiento de las matemáticas tal y como se entienden cotidianemente (ecuaciones y esas cosas).</p>
        </section>
        </section>
        <section id="eficiencia" class="level1">
        <h1>Eficiencia</h1>
        <section id="intro" class="level2">
        <h2>Intro</h2>
        <p>Para medir la eficiencia de cualquier algoritmo o instrucción, tenemos dos maneras. La primera es leer el framerate y la segunda (mejor) medir el tiempo total que toma ejecutarlo. Ambas soluciones son útiles en la medida que permiten comparar soluciones distintas:</p>
        <pre><code>
        //Ejemplo de cómo medir el tiempo de un algoritmo
        println(frameRate());         //Primera manera
        int start = millis();
        uberAlgorithm();         
        println( millis() - start );  //Segunda manera
        </code></pre>
        <p>Son pruebas muy básicas, aunque perfectamente válidas para nuestros intereses. Para medir correctamente la eficiencia de un programa o instrucción se usan programas o plugins especiales llamados <em>profilers</em> que tienen en cuenta muchas más cosas y que ayudan a detectar los cuellos de botella.</p>
        </section>
        <section id="coste-de-un-algoritmo" class="level2">
        <h2>Coste de un algoritmo</h2>
        <p>El coste de un algoritmo se puede entender como la suma de los costes de las operaciones que éste comprende por su frecuencia y, lógicamente, es inversamente proporcional a su eficiencia. Esto quiere decir que <strong>tenemos dos maneras de mejorar la eficiencia de un algoritmo</strong>: reducir el coste de las operaciones o reducir su frecuencia. La primera entraría en lo que podríamos denominar <em>micro-optimización</em>, y la segunda sería el terreno de la optimización algorítmica propiamente dicha.</p>
        </section>
        <section id="micro-eficiencia" class="level2">
        <h2>Micro-eficiencia</h2>
        <p>Como ya hemos adelantado la micro-eficiencia tiene que ver con pequeñas mejoras en un algoritmo que generalmente lo que hacen es reducir la complejidad de las operaciones necesarias, o que hacen pequeños cambios <em>que no alteran el orden de complejidad de un algoritmo</em>.</p>
        <p>Hay buenas prácticas en este sentido. Por ejemplo:</p>
        <ul>
        <li>Si repites el mismo cálculo continuamente, guárdalo en una variable. Si es un conjunto de valores usa una matriz (<em>lookup table</em>)</li>
        <li>Si tienes que comprobar varias condiciones en un único condicional, comprueba primero siempre la más barata.</li>
        <li>Si tienes que copiar los valores de una matriz, no iteres por la misma y usa <em>arrayCopy</em>, que funciona a bajo nivel y es mucho más rápida.</li>
        <li>Los Strings son objetos invariables. Esto significa que si cambias un String lo que haces es, realmente, generar otro nuevo. Si vas a estar trabajando con Strings mutables usa otras clases como StringBuffer o StringBuilder.</li>
        </ul>
        </section>
        <section id="ejemploi.-micro-optimización.-lookup-tables." class="level2">
        <h2>Ejemplo(I). Micro-optimización. Lookup Tables.</h2>
        <p><em>Lookup Tables</em> (o LUT) es como se llama en programación a aquellas <em>tablas</em> donde se guardan datos que se van a reusar durante el ciclo de vida de un programa. Este enfoque merece la pena cuando hay valores de cálculo costoso que se calculan continuamente durante la ejecución (en el <em>draw</em> de processing, p.ej.). Aunque se llaman tablas, en la práctica suelen ser arrays (u otras estructuras de datos). Su uso por ejemplo: cachear un campo de fuerzas basado en <em>noise</em>, cachear cálculos trigonométricos, etc.</p>
        </section>
        <section id="cuellos-de-botella" class="level2">
        <h2>Cuellos de botella</h2>
        <p>Los cuellos de botella son las peores secciones de un programa a efectos de eficiencia. <strong>En processing, casi siempre, los cuellos de botella tienen que ver con la representación gráfica</strong>. Esto significa que aunque haya mejoras evidentes en términos de micro-optimización, es probable que aplicando esas mejoras no consigamos ninguna mejora apreciable en la ejecución de nuestro programa. Por ejemplo: podemos cachear el resultado de una operación matemática para evitar realizarla 100 veces por segundo pero si además en cada frame dibujamos 3000 formas con transparencia, el ordenador tiene que calcular los píxeles resultantes y esa operación es tan cara que la otra es una mejora imperceptible.</p>
        </section>
        </section>
        <section id="orden-de-complejidad" class="level1">
        <h1>Orden de complejidad</h1>
        <section id="definición" class="level2">
        <h2>Definición</h2>
        <p>El orden de complejidad de un algoritmo (O) es la manera más usual de medir la frecuencia de operaciones que este realiza en función del número de inputs. Por ejemplo, un orden de complejidad lineal, <em>O(n)</em>, es aquel en el que el número de operaciones es directamente proporcional al número de elementos:</p>
        <pre><code>
        //Ejemplo de operación lineal O(n)
        Elem[] elements = new Elem[500];
        for(int i = 0; i &lt; elements.length; i++)
            elements[i].doThat();
        
        //Ejemplo de operación lineal O(5n)
        Elem[] elements = new Elem[500];
        for(int i = 0; i &lt; elements.length; i++)
            for(int j = 0; j &lt; 5; j++)
                elements[i].doThat();
        
        </code></pre>
        </section>
        <section id="los-algoritmos-de-fuerza-bruta" class="level2">
        <h2>Los algoritmos de fuerza bruta</h2>
        <p>Los algoritmos de fuerza bruta son la manera más obvia de plantear la solución a un problema algorítmico y consisten en encontrar el resultado recorriendo todo el espacio de soluciones, siendo siempre la manera de complejidad teórica máxima de resolver un problema.</p>
        </section>
        <section id="un-ejemplo-búsqueda-por-fuerza-bruta..." class="level2">
        <h2>Un ejemplo: búsqueda por fuerza bruta...</h2>
        <p>Vamos a plantear un ejemplo muy sencillo. Tenemos un array y queremos saber si contiene un determinado valor. La solución de fuerza bruta es la obvia, recorrer todo el espacio de soluciones (el array) y preguntarle a cada elemento si es el que buscamos:</p>
        <pre><code>
        float[] valores = new float[5000];
        for(int i = 0; i &lt; valores.length; i++) valores = random(5000);
        //Queremos saber si en _valores_ existe el valor 5.2
        for(int i = 0; i &lt; valores.length; i++)
            if(valores[i] == 5.2) println(&quot;Eureka!&quot;);
        </code></pre>
        <p>En este caso el orden de complejidad es lineal ya que el número de operaciones es proporcional directamente al número de elementos.</p>
        </section>
        <section id="y-binary-search.-orden-de-complejidad-logarítmico." class="level2">
        <h2>...y <em>binary search</em>. Orden de complejidad logarítmico.</h2>
        <p>Pero hay una manera más inteligente de resolver este problema, llamado <em>búsqueda binaria</em>. Tenemos que ordenar la bolsa primero según el tipo de valor y después buscar éste, comprobando el valor que divide la bolsa por la mitad. Si el valor es mayor buscamos en la bolsa superior y desechamos la inferior (y viceversa). Este tipo de planteamientos que subdividen recurrentemente el espacio de soluciones por la mitad tienen un coste logarítmico <em>O(log n)</em>, ya que el logaritmo en base 2 de un número viene a representar el máximo número de veces que puedes dividir ese valor por la mitad. <strong>Importante:</strong> <em>en programación los logaritmos son en base 2</em>. Evidentemente ordenar la bolsa tiene un coste que hay que tener en cuenta, pero si la bolsa no va a cambiar y vamos a estar continuamente buscando valores la mejora puede ser muy importante. Supongamos que tenemos que buscar en una base de datos de la población de China un determinado registro y que comprobar cada uno nos cuesta un milisegundo. En el peor de los casos (el registro no tiene coincidencias en la base) necesitaríamos un ordenador funcionando durante 16 días seguidos para recorrer todos los registros (1400 millones). Usando binary search gastaríamos un tiempo inicial en ordenar (que se puede minimizar usando una estructura de datos auto-ordenable como un <em>binary heap</em>), pero la comprobación habría que hacerla, a lo sumo unas 31 veces (el máximo número de veces que puedes dividir por dos 1400 millones). Es decir, tardaríamos medio segundo.</p>
        </section>
        <section id="binary-search" class="level2">
        <h2>Binary Search</h2>
        <p><em>Implementación de Robert Sedgewick y Kevin Wayne</em></p>
        <pre><code>
        public class BinarySearch
        {
            public static int rank(int key, int[] a)
            {
                int lo = 0;
                int hi = a.length - 1;
                while (lo &lt;= hi)
                {
                    int mid = lo + (hi - lo) / 2;
                    if      (key &lt; a[mid]) hi = mid - 1;
                    else if (key &gt; a[mid]) lo = mid + 1;
                    else                     return mid;
                }
                return -1;
            }
        }
        </code></pre>
        <p>Importante: <strong>nunca hay que reinventar la rueda</strong></p>
        </section>
        <section id="orden-de-complejidad-cuadrático.-el-nns." class="level2">
        <h2>Orden de complejidad cuadrático. El NNS.</h2>
        <p>El orden de complejidad cuadrático O(n^2) empieza a ser un orden de complejidad alto. Muchos de los algoritmos clásicos transforman problemas que tienen un orden de complejidad cuadrático en un orden de complejidad <em>linearítmico</em> O(n*log n). Un ejemplo muy evidente es el algoritmo de búsqueda del vecino más cercano (<em>nearest neighbour search</em> o NNS). En un algoritmo de este tipo recorremos todo el espacio de valores íntegramente por cada elemento para comprobar la distancia de todos los elementos entre sí:</p>
        <pre><code>
        //Ejemplo de NNS
        Elem[] elements = new Elem[500];
        for(int i = 0; i &lt; elements.length; i++)
            for(int j = 0; j &lt; elements.length; j++)
                if(i != j &amp;&amp; elements[i].dist(elements[j]) &lt; distance_treshold)
                doWhatever();
        </code></pre>
        <p>Este es un algoritmo clásico en gráfica generativa y es usado extensivamente, por ejemplo, por Casey Reas en sus procesos.</p>
        </section>
        <section id="ejemploii.-optimización-de-un-nns." class="level2">
        <h2>Ejemplo(II). Optimización de un NNS.</h2>
        <p>En este ejemplo vamos a ver como podemos optimizar el algoritmo anterior, sin introducir ningún algoritmo especial, repasando varias técnicas de micro-optimización y reparando en un error habitual que se suele cometer en las iteraciones de los NNS.</p>
        </section>
        </section>
        <section id="reduciendo-la-complejidad-del-nns.-hash-grids." class="level1">
        <h1>Reduciendo la complejidad del NNS. Hash-grids.</h1>
        <section id="intro-1" class="level2">
        <h2>Intro</h2>
        <p>Como hemos adelantado hay bastantes algoritmos clásicos que permiten reducir una complejidad cuadrática a un orden linearítmico (FFT que se usan en análisis de audio, el algoritmo de Dijkstra para saber el recorrido mínimo entre dos puntos, los algoritmos de búsqueda clásicos como el quicksort...). Ese es este caso, en el que vamos a usar un algoritmo de <em>space partitioning</em>, para reducir la complejidad cuadrática del algoritmo de búsqueda del vecino más cercano. Los algoritmos de <em>space partitioning</em> dividen el espacio, como indica su nombre, con la idea de deshechar a priori el máximo número de comparaciones de distancia. Los hash-grids son los más sencillos y tienen un enfoque particular que es el de ser los más eficientes cuando la distribución de elementos es más o menos homogénea.</p>
        </section>
        <section id="funcionamiento" class="level2">
        <h2>Funcionamiento</h2>
        <p>Un hash-grid es una rejilla ortogonal de cuadrados, que en el código llamaremos <em>buckets</em>. Esta rejilla está respaldada en una lista donde introducimos en cada frame a las partículas. De manera que es muy fácil saber en todo momento en que bucket se encuentra una partícula en concreto. Haremos la rejilla de manera que la distancia umbral que nos interesa comprobar sea como máximo del tamaño de los buckets. De esa manera sabemos que los vecinos de una partícula en concreto, estarán <strong>siempre</strong> en los buckets que rodean a la partícula en cuestión. De esa manera reducimos las comprobaciones de una partícula a todas las demás a de una partícula a todas las de los buckets que la rodean. Matemáticamente está comprobado que este acercamiento suele producir un orden de complejidad O(n log n).</p>
        </section>
        </section>
        <section id="una-imagen-vale-más-que-mil-palabras" class="level1">
        <h1>Una imagen vale más que mil palabras</h1>
        <figure>
        <img src="imgs/hashgrid.png" alt="Representación de un grupo de partículas sobre un hashgrid. Los puntos ocre son los vecinos más cercanos del punto rojo." /><figcaption>Representación de un grupo de partículas sobre un hashgrid. Los puntos ocre son los vecinos más cercanos del punto rojo.</figcaption>
        </figure>
        </section>
        <section id="ejemploiii.-hash-grids." class="level1">
        <h1>Ejemplo(III). Hash-grids.</h1>
        </section>
        </div>
         
        <script src="../../revealjs/lib/js/head.min.js"></script>
        <script src="../../revealjs/js/reveal.js"></script>
         
        <script>
            // Full list of configuration options available here:
            // https://github.com/hakimel/reveal.js#configuration
            Reveal.initialize({
                controls: true,
                progress: true,
                history: true,
                center: false,
                // available themes are in /css/theme
                                theme: Reveal.getQueryHash().theme || 'black',
                                // default/cube/page/concave/zoom/linear/fade/none
                                transition: Reveal.getQueryHash().transition || 'slide',
                                // Optional libraries used to extend on reveal.js
                dependencies: [
                    { src: '../../revealjs/lib/js/classList.js', condition: function() { return !document.body.classList; } },
                    { src: '../../revealjs/plugin/markdown/showdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
                    { src: '../../revealjs/plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
                    { src: '../../revealjs/plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
                    { src: '../../revealjs/plugin/zoom-js/zoom.js', async: true, condition: function() { return !!document.body.classList; } },
                    { src: '../../revealjs/plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } }
                ]
            });
        </script>
    </body>
</html> 
